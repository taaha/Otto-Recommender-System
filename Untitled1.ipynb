{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64821ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get the list of files in the data directory\n",
    "file_list = [f for f in os.listdir('data/train_parquet') if f.endswith('.parquet')]\n",
    "\n",
    "# Prepend the directory path to each file name\n",
    "file_list = [os.path.join('data/train_parquet', f) for f in file_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc455e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/train_parquet/000100000_000200000.parquet',\n",
       " 'data/train_parquet/000900000_001000000.parquet',\n",
       " 'data/train_parquet/012200000_012300000.parquet',\n",
       " 'data/train_parquet/012100000_012200000.parquet',\n",
       " 'data/train_parquet/011400000_011500000.parquet',\n",
       " 'data/train_parquet/008800000_008900000.parquet',\n",
       " 'data/train_parquet/002800000_002900000.parquet',\n",
       " 'data/train_parquet/004000000_004100000.parquet',\n",
       " 'data/train_parquet/007700000_007800000.parquet',\n",
       " 'data/train_parquet/001700000_001800000.parquet',\n",
       " 'data/train_parquet/009900000_010000000.parquet',\n",
       " 'data/train_parquet/005500000_005600000.parquet',\n",
       " 'data/train_parquet/010900000_011000000.parquet',\n",
       " 'data/train_parquet/009700000_009800000.parquet',\n",
       " 'data/train_parquet/005900000_006000000.parquet',\n",
       " 'data/train_parquet/010400000_010500000.parquet',\n",
       " 'data/train_parquet/002200000_002300000.parquet',\n",
       " 'data/train_parquet/003700000_003800000.parquet',\n",
       " 'data/train_parquet/001400000_001500000.parquet',\n",
       " 'data/train_parquet/005000000_005100000.parquet',\n",
       " 'data/train_parquet/003400000_003500000.parquet',\n",
       " 'data/train_parquet/009000000_009100000.parquet',\n",
       " 'data/train_parquet/006500000_006600000.parquet',\n",
       " 'data/train_parquet/010700000_010800000.parquet',\n",
       " 'data/train_parquet/004800000_004900000.parquet',\n",
       " 'data/train_parquet/011900000_012000000.parquet',\n",
       " 'data/train_parquet/012500000_012600000.parquet',\n",
       " 'data/train_parquet/012800000_012900000.parquet',\n",
       " 'data/train_parquet/000700000_000800000.parquet',\n",
       " 'data/train_parquet/007600000_007700000.parquet',\n",
       " 'data/train_parquet/001100000_001200000.parquet',\n",
       " 'data/train_parquet/003900000_004000000.parquet',\n",
       " 'data/train_parquet/004900000_005000000.parquet',\n",
       " 'data/train_parquet/011800000_011900000.parquet',\n",
       " 'data/train_parquet/012700000_012800000.parquet',\n",
       " 'data/train_parquet/010100000_010200000.parquet',\n",
       " 'data/train_parquet/006000000_006100000.parquet',\n",
       " 'data/train_parquet/009800000_009900000.parquet',\n",
       " 'data/train_parquet/002100000_002200000.parquet',\n",
       " 'data/train_parquet/002700000_002800000.parquet',\n",
       " 'data/train_parquet/011000000_011100000.parquet',\n",
       " 'data/train_parquet/002500000_002600000.parquet',\n",
       " 'data/train_parquet/010300000_010400000.parquet',\n",
       " 'data/train_parquet/000800000_000900000.parquet',\n",
       " 'data/train_parquet/000400000_000500000.parquet',\n",
       " 'data/train_parquet/002300000_002400000.parquet',\n",
       " 'data/train_parquet/005200000_005300000.parquet',\n",
       " 'data/train_parquet/010200000_010300000.parquet',\n",
       " 'data/train_parquet/007500000_007600000.parquet',\n",
       " 'data/train_parquet/001800000_001900000.parquet',\n",
       " 'data/train_parquet/005100000_005200000.parquet',\n",
       " 'data/train_parquet/010000000_010100000.parquet',\n",
       " 'data/train_parquet/001000000_001100000.parquet',\n",
       " 'data/train_parquet/004500000_004600000.parquet',\n",
       " 'data/train_parquet/011700000_011800000.parquet',\n",
       " 'data/train_parquet/007900000_008000000.parquet',\n",
       " 'data/train_parquet/008000000_008100000.parquet',\n",
       " 'data/train_parquet/006700000_006800000.parquet',\n",
       " 'data/train_parquet/012400000_012500000.parquet',\n",
       " 'data/train_parquet/008400000_008500000.parquet',\n",
       " 'data/train_parquet/000300000_000400000.parquet',\n",
       " 'data/train_parquet/006600000_006700000.parquet',\n",
       " 'data/train_parquet/011200000_011300000.parquet',\n",
       " 'data/train_parquet/011300000_011400000.parquet',\n",
       " 'data/train_parquet/001900000_002000000.parquet',\n",
       " 'data/train_parquet/001200000_001300000.parquet',\n",
       " 'data/train_parquet/004400000_004500000.parquet',\n",
       " 'data/train_parquet/008100000_008200000.parquet',\n",
       " 'data/train_parquet/006100000_006200000.parquet',\n",
       " 'data/train_parquet/003800000_003900000.parquet',\n",
       " 'data/train_parquet/005400000_005500000.parquet',\n",
       " 'data/train_parquet/005300000_005400000.parquet',\n",
       " 'data/train_parquet/007300000_007400000.parquet',\n",
       " 'data/train_parquet/000600000_000700000.parquet',\n",
       " 'data/train_parquet/007800000_007900000.parquet',\n",
       " 'data/train_parquet/009200000_009300000.parquet',\n",
       " 'data/train_parquet/010800000_010900000.parquet',\n",
       " 'data/train_parquet/007200000_007300000.parquet',\n",
       " 'data/train_parquet/003500000_003600000.parquet',\n",
       " 'data/train_parquet/012000000_012100000.parquet',\n",
       " 'data/train_parquet/004200000_004300000.parquet',\n",
       " 'data/train_parquet/004600000_004700000.parquet',\n",
       " 'data/train_parquet/011100000_011200000.parquet',\n",
       " 'data/train_parquet/010500000_010600000.parquet',\n",
       " 'data/train_parquet/011500000_011600000.parquet',\n",
       " 'data/train_parquet/009400000_009500000.parquet',\n",
       " 'data/train_parquet/008700000_008800000.parquet',\n",
       " 'data/train_parquet/004300000_004400000.parquet',\n",
       " 'data/train_parquet/004100000_004200000.parquet',\n",
       " 'data/train_parquet/002900000_003000000.parquet',\n",
       " 'data/train_parquet/003000000_003100000.parquet',\n",
       " 'data/train_parquet/009100000_009200000.parquet',\n",
       " 'data/train_parquet/001500000_001600000.parquet',\n",
       " 'data/train_parquet/008200000_008300000.parquet',\n",
       " 'data/train_parquet/009600000_009700000.parquet',\n",
       " 'data/train_parquet/006400000_006500000.parquet',\n",
       " 'data/train_parquet/007000000_007100000.parquet',\n",
       " 'data/train_parquet/008500000_008600000.parquet',\n",
       " 'data/train_parquet/003600000_003700000.parquet',\n",
       " 'data/train_parquet/004700000_004800000.parquet',\n",
       " 'data/train_parquet/000200000_000300000.parquet',\n",
       " 'data/train_parquet/009300000_009400000.parquet',\n",
       " 'data/train_parquet/005800000_005900000.parquet',\n",
       " 'data/train_parquet/005600000_005700000.parquet',\n",
       " 'data/train_parquet/012600000_012700000.parquet',\n",
       " 'data/train_parquet/002000000_002100000.parquet',\n",
       " 'data/train_parquet/006200000_006300000.parquet',\n",
       " 'data/train_parquet/003200000_003300000.parquet',\n",
       " 'data/train_parquet/006300000_006400000.parquet',\n",
       " 'data/train_parquet/001600000_001700000.parquet',\n",
       " 'data/train_parquet/006900000_007000000.parquet',\n",
       " 'data/train_parquet/000500000_000600000.parquet',\n",
       " 'data/train_parquet/008300000_008400000.parquet',\n",
       " 'data/train_parquet/008600000_008700000.parquet',\n",
       " 'data/train_parquet/009500000_009600000.parquet',\n",
       " 'data/train_parquet/003100000_003200000.parquet',\n",
       " 'data/train_parquet/000000000_000100000.parquet',\n",
       " 'data/train_parquet/005700000_005800000.parquet',\n",
       " 'data/train_parquet/012300000_012400000.parquet',\n",
       " 'data/train_parquet/002400000_002500000.parquet',\n",
       " 'data/train_parquet/011600000_011700000.parquet',\n",
       " 'data/train_parquet/007100000_007200000.parquet',\n",
       " 'data/train_parquet/007400000_007500000.parquet',\n",
       " 'data/train_parquet/006800000_006900000.parquet',\n",
       " 'data/train_parquet/010600000_010700000.parquet',\n",
       " 'data/train_parquet/002600000_002700000.parquet',\n",
       " 'data/train_parquet/003300000_003400000.parquet',\n",
       " 'data/train_parquet/001300000_001400000.parquet',\n",
       " 'data/train_parquet/008900000_009000000.parquet']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "128cbfce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 129/129 [00:05<00:00, 21.64it/s]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql import SparkSession\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Create a SparkSession\n",
    "#spark = SparkSession.builder.getOrCreate()\n",
    "spark = SparkSession.builder \\\n",
    "    .config('spark.driver.memory', '24g') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Initialize an empty list to store the DataFrames\n",
    "df_list = []\n",
    "\n",
    "# Iterate through the list of Parquet files\n",
    "for file in tqdm(file_list):\n",
    "    # Read the Parquet file into a Spark DataFrame\n",
    "    df = spark.read.parquet(file)\n",
    "\n",
    "    # Append the DataFrame to the list\n",
    "    df_list.append(df)\n",
    "\n",
    "# Concatenate the DataFrames in the list\n",
    "#df = df_list[0].union(df_list[1:])\n",
    "df = df_list[0]\n",
    "\n",
    "# Iterate through the rest of the DataFrames in the list\n",
    "for i in range(1, len(df_list)):\n",
    "    # Union the DataFrame with the next DataFrame in the list\n",
    "    df = df.union(df_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a87efd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----+\n",
      "|session|    aid|type|\n",
      "+-------+-------+----+\n",
      "| 100000|1498214|   1|\n",
      "| 100000|1617298|   1|\n",
      "| 100000|1617298|   3|\n",
      "| 100000|1820189|   1|\n",
      "| 100000|1619534|   1|\n",
      "| 100000|  22770|   1|\n",
      "| 100000|  22770|   1|\n",
      "| 100000|  22770|   3|\n",
      "| 100000| 339965|   1|\n",
      "| 100000| 339965|   3|\n",
      "| 100000| 339965|   5|\n",
      "| 100000|  22770|   5|\n",
      "| 100000| 339965|   1|\n",
      "| 100000| 339965|   1|\n",
      "| 100000| 710289|   1|\n",
      "| 100001|1104009|   1|\n",
      "| 100001|1196408|   1|\n",
      "| 100001| 822736|   1|\n",
      "| 100001| 791744|   1|\n",
      "| 100001| 822736|   1|\n",
      "+-------+-------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "568a8e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/08 23:40:31 WARN DAGScheduler: Broadcasting large task binary with size 1255.5 KiB\n",
      "23/01/08 23:40:32 WARN DAGScheduler: Broadcasting large task binary with size 1255.5 KiB\n",
      "23/01/08 23:40:32 WARN DAGScheduler: Broadcasting large task binary with size 1257.7 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 392:====================================================>(308 + 1) / 309]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/08 23:41:01 WARN DAGScheduler: Broadcasting large task binary with size 1259.3 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 393:===================================================> (302 + 4) / 309]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/08 23:41:25 WARN DAGScheduler: Broadcasting large task binary with size 1260.6 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/08 23:41:48 WARN DAGScheduler: Broadcasting large task binary with size 1259.6 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 396:====================================================>(308 + 1) / 309]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/08 23:42:14 WARN DAGScheduler: Broadcasting large task binary with size 1260.9 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/08 23:43:23 WARN DAGScheduler: Broadcasting large task binary with size 1261.6 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 401:============================================>           (8 + 2) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/08 23:43:44 WARN DAGScheduler: Broadcasting large task binary with size 1264.6 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 402:==================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/08 23:44:39 WARN DAGScheduler: Broadcasting large task binary with size 1266.0 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 403:============================================>           (8 + 2) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/08 23:45:55 WARN DAGScheduler: Broadcasting large task binary with size 1267.4 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 404:============================================>           (8 + 2) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/08 23:46:42 WARN DAGScheduler: Broadcasting large task binary with size 1268.8 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 405:==================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/08 23:47:53 WARN DAGScheduler: Broadcasting large task binary with size 1270.2 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 406:============================================>           (8 + 2) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/08 23:48:40 WARN DAGScheduler: Broadcasting large task binary with size 1271.6 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 407:==================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/08 23:49:51 WARN DAGScheduler: Broadcasting large task binary with size 1273.0 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 408:==================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/08 23:50:38 WARN DAGScheduler: Broadcasting large task binary with size 1274.3 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 409:==================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/08 23:51:49 WARN DAGScheduler: Broadcasting large task binary with size 1275.7 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 410:==================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/08 23:52:38 WARN DAGScheduler: Broadcasting large task binary with size 1277.7 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/08 23:53:37 WARN DAGScheduler: Broadcasting large task binary with size 1276.3 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Train the ALS model\n",
    "als = ALS(maxIter=5, regParam=0.01, userCol=\"session\", itemCol=\"aid\", ratingCol=\"type\")\n",
    "model = als.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aff2ea71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/08 23:57:37 WARN DAGScheduler: Broadcasting large task binary with size 1290.3 KiB\n",
      "23/01/08 23:57:37 WARN DAGScheduler: Broadcasting large task binary with size 1288.9 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 440:==================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/08 23:57:45 WARN DAGScheduler: Broadcasting large task binary with size 1634.1 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 456:==================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/08 23:57:46 WARN DAGScheduler: Broadcasting large task binary with size 1648.7 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/08 23:57:47 WARN DAGScheduler: Broadcasting large task binary with size 1648.7 KiB\n",
      "+-------+-------+----+----------+\n",
      "|session|    aid|type|prediction|\n",
      "+-------+-------+----+----------+\n",
      "|     42| 979267|   1| 1.3249768|\n",
      "|     42| 979267|   1| 1.3249768|\n",
      "|     42|1648297|   1| 1.2555958|\n",
      "|     42| 515648|   1| 1.2414193|\n",
      "|     42| 645446|   1| 0.9764026|\n",
      "|     42|1325950|   1| 1.3869649|\n",
      "|     42|1745778|   1| 1.4822401|\n",
      "|     42|  20376|   1| 1.0719389|\n",
      "|     42| 925260|   1| 0.8904284|\n",
      "|     42|1041839|   1| 1.6788143|\n",
      "|     42|1263386|   1| 1.0875018|\n",
      "|     42|1610035|   3| 1.4072871|\n",
      "|     42|1779951|   1| 1.3508937|\n",
      "|     42|1779951|   1| 1.3508937|\n",
      "|     42|1779951|   3| 1.3508937|\n",
      "|     42| 536610|   1| 1.1745937|\n",
      "|     42| 670233|   1|0.91651434|\n",
      "|     42|1228562|   1| 0.9530386|\n",
      "|     42|1527697|   1|  1.309192|\n",
      "|     42|1671956|   1| 1.1216995|\n",
      "+-------+-------+----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make recommendations for a user\n",
    "recommendations = model.transform(df.filter(df.session == 42))\n",
    "\n",
    "# Show the recommendations\n",
    "recommendations.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b17b55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a884bbd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
